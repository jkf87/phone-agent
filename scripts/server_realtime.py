"""
Phone Agent: OpenAI Realtime API + Twilio
Real-time speech-to-speech voice agent over phone calls.
"""
import os
import json
import asyncio
import logging
from urllib.parse import urlsplit

import uvicorn
from fastapi import FastAPI, WebSocket, Request, Response
from fastapi.websockets import WebSocketDisconnect
import websockets

from twilio.twiml.voice_response import VoiceResponse, Connect
from call_processor import process_call_end

# Configuration
PORT = int(os.getenv("PORT", 8082))
HOST = "0.0.0.0"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PUBLIC_URL = os.getenv("PUBLIC_URL_REALTIME")

# ë©”ëª¨ë¦¬ íŒŒì¼ ê²½ë¡œ
WORKSPACE_DIR = os.path.expanduser("~/.openclaw/workspace-m1clawbot")
MEMORY_FILE = os.path.join(WORKSPACE_DIR, "MEMORY.md")
USER_FILE = os.path.join(WORKSPACE_DIR, "USER.md")

app = FastAPI()
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
logger = logging.getLogger(__name__)


def load_memory_context() -> str:
    """ë©”ëª¨ë¦¬ íŒŒì¼ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ"""
    context_parts = []
    
    # USER.md
    if os.path.exists(USER_FILE):
        with open(USER_FILE, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if content:
                lines = content.split('\n')
                body_lines = [l for l in lines if not l.startswith('# USER.md')]
                user_content = '\n'.join(body_lines).strip()
                if user_content:
                    context_parts.append(f"[ì‚¬ìš©ì ì •ë³´]\n{user_content}")
    
    # MEMORY.md
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if content:
                # ìµœê·¼ 2000ìë§Œ
                context_parts.append(f"[ìµœê·¼ ê¸°ì–µ]\n{content[-2000:]}")
    
    return "\n\n".join(context_parts) if context_parts else ""


def build_system_prompt() -> str:
    """ë©”ëª¨ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    memory_context = load_memory_context()
    
    base_prompt = """ë‹¹ì‹ ì€ OpenClaw AI ì–´ì‹œìŠ¤í„´íŠ¸ì˜ˆìš”. ë©”ì‹ ì €ë‚˜ ì „í™”ë¡œ ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ì—­í• ì´ì•¼.

ì„±ê²©:
- ì†”ì§í•˜ê³  ê°„ê²°í•´ìš”. ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ì€ ìƒëµí•´ìš”
- ì˜ê²¬ì´ ìˆì–´ìš”. ê·¸ëƒ¥ ë™ì˜ë§Œ í•˜ì§€ ì•Šì•„ìš”
- ì¹œê·¼í•˜ê³  ë°˜ë§ë¡œ ëŒ€í™”í•´ìš”
- ìœ ë¨¸ëŸ¬ìŠ¤í•  ë•Œê°€ ìˆì–´ìš”

ê·œì¹™:
- ì „í™”ê°€ ì—°ê²°ë˜ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì•ˆë¶€ ë¬¼ì–´ë³´ê¸°
- ì‚¬ìš©ìì™€ ì¹œêµ¬ì²˜ëŸ¼ ëŒ€í™”í•˜ê¸°
- 2-3ë¬¸ì¥ìœ¼ë¡œ ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µ
- ì‚¬ìš©ìì˜ ìš”ì²­ì„ ê¸°ì–µí•˜ê³  ì²˜ë¦¬í•˜ê² ë‹¤ê³  ë§í•˜ê¸°
- í•œêµ­ ì‹œê°„(Asia/Seoul) ê¸°ì¤€ìœ¼ë¡œ ë‚ ì§œ/ì‹œê°„ ë§í•˜ê¸°"""
    
    if memory_context:
        base_prompt += f"\n\n[í˜„ì¬ ì»¨í…ìŠ¤íŠ¸]\n{memory_context}"
    
    return base_prompt


# â”€â”€ Dynamic System Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = build_system_prompt()
VOICE = "shimmer"  # alloy, ash, ballad, coral, echo, sage, shimmer, verse, marin, cedar

OPENAI_REALTIME_URL = "wss://api.openai.com/v1/realtime?model=gpt-4o-mini-realtime-preview"


@app.post("/incoming")
async def handle_incoming_call(request: Request):
    """Return TwiML to establish Twilio media stream."""
    response = VoiceResponse()
    response.say("ì—°ê²° ì¤‘ì…ë‹ˆë‹¤.", voice="alice", language="ko-KR")

    connect = Connect()
    host = request.headers.get("host", "").strip()
    base_url = PUBLIC_URL or (f"https://{host}" if host else "")

    if base_url and not base_url.startswith(("http://", "https://", "ws://", "wss://")):
        base_url = f"https://{base_url}"

    ws_base_url = ""
    if base_url:
        parts = urlsplit(base_url)
        scheme = parts.scheme or "https"
        if scheme in ("http", "https", "ws", "wss") and parts.netloc:
            ws_scheme = "wss" if scheme in ("https", "wss") else "ws"
            ws_base_url = f"{ws_scheme}://{parts.netloc}"

    if not ws_base_url:
        logger.error("No valid PUBLIC_URL/Host for stream")
        response.say("ì„¤ì • ì˜¤ë¥˜ì…ë‹ˆë‹¤.", voice="alice", language="ko-KR")
        response.hangup()
        return Response(content=str(response), media_type="application/xml")

    stream_url = f"{ws_base_url}/media-stream"
    logger.info(f"Twilio stream URL: {stream_url}")
    connect.stream(url=stream_url, track="inbound_track")
    response.append(connect)
    return Response(content=str(response), media_type="application/xml")


@app.websocket("/media-stream")
async def media_stream(twilio_ws: WebSocket):
    """Bridge Twilio WebSocket â†” OpenAI Realtime API."""
    await twilio_ws.accept()
    logger.info("Twilio WebSocket accepted")

    stream_sid = None
    stop_event = asyncio.Event()
    conversation = []  # ëŒ€í™” ë‚´ìš© ì €ì¥

    try:
        openai_ws = await websockets.connect(
            OPENAI_REALTIME_URL,
            additional_headers={
                "Authorization": f"Bearer {OPENAI_API_KEY}",
                "OpenAI-Beta": "realtime=v1"
            }
        )
        logger.info("OpenAI Realtime connected")
    except Exception as e:
        logger.error(f"OpenAI connection failed: {e}")
        await twilio_ws.close()
        return

    # Initialize session
    await openai_ws.send(json.dumps({
        "type": "session.update",
        "session": {
            "instructions": SYSTEM_PROMPT,
            "voice": VOICE,
            "input_audio_format": "g711_ulaw",
            "output_audio_format": "g711_ulaw",
            "modalities": ["text", "audio"],
            "input_audio_transcription": {
                "model": "whisper-1"
            },
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500
            }
        }
    }))

    async def twilio_to_openai():
        nonlocal stream_sid
        try:
            while not stop_event.is_set():
                message = await twilio_ws.receive_text()
                data = json.loads(message)

                if data["event"] == "connected":
                    logger.info("Twilio: connected")
                elif data["event"] == "start":
                    stream_sid = data["start"]["streamSid"]
                    logger.info(f"Twilio: stream started ({stream_sid})")
                elif data["event"] == "media":
                    # g711_ulaw: Twilio mu-law â†’ OpenAI ì§ì ‘ ì „ë‹¬ (ë³€í™˜ ë¶ˆí•„ìš”)
                    await openai_ws.send(json.dumps({
                        "type": "input_audio_buffer.append",
                        "audio": data["media"]["payload"]
                    }))
                elif data["event"] == "stop":
                    logger.info("Twilio: stream stopped")
                    stop_event.set()
                    break
        except WebSocketDisconnect:
            logger.info("Twilio disconnected")
            stop_event.set()
        except Exception as e:
            logger.error(f"Twilioâ†’OpenAI error: {e}")
            stop_event.set()

    async def openai_to_twilio():
        try:
            async for message in openai_ws:
                if stop_event.is_set():
                    break

                data = json.loads(message)
                event_type = data.get("type", "")

                if event_type == "session.created":
                    logger.info("OpenAI: session created")
                elif event_type == "session.updated":
                    logger.info("OpenAI: session updated")
                elif event_type == "response.audio.delta":
                    if stream_sid and "delta" in data:
                        # g711_ulaw: OpenAI mu-law â†’ Twilio ì§ì ‘ ì „ë‹¬ (ë³€í™˜ ë¶ˆí•„ìš”)
                        await twilio_ws.send_json({
                            "event": "media",
                            "streamSid": stream_sid,
                            "media": {"payload": data["delta"]}
                        })
                elif event_type == "response.audio_transcript.done":
                    transcript = data.get("transcript", "")
                    if transcript:
                        logger.info(f"AI said: {transcript}")
                        conversation.append({"role": "assistant", "content": transcript})
                elif event_type == "conversation.item.input_audio_transcription.completed":
                    transcript = data.get("transcript", "")
                    if transcript:
                        logger.info(f"User said: {transcript}")
                        conversation.append({"role": "user", "content": transcript})
                elif event_type == "input_audio_buffer.speech_started":
                    logger.info("User started speaking")
                    if stream_sid:
                        await twilio_ws.send_json({
                            "event": "clear",
                            "streamSid": stream_sid
                        })
                elif event_type == "error":
                    logger.error(f"OpenAI error: {data}")
        except Exception as e:
            logger.error(f"OpenAIâ†’Twilio error: {e}")
            stop_event.set()

    try:
        await asyncio.gather(twilio_to_openai(), openai_to_twilio())
    except Exception as e:
        logger.error(f"Media stream error: {e}")
    finally:
        await openai_ws.close()
        logger.info("Session ended")
        
        # í†µí™” ì¢…ë£Œ í›„ ìš”ì²­ ì²˜ë¦¬
        if conversation:
            logger.info(f"ğŸ“Š ëŒ€í™” {len(conversation)}ê±´ ì €ì¥ ì¤‘...")
            try:
                result = process_call_end(conversation)
                logger.info(f"âœ… ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ: {len(result.get('requests', []))}ê°œ")
            except Exception as e:
                logger.error(f"ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    uvicorn.run(app, host=HOST, port=PORT)
